{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Munich Airbnb Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**: The used datasets were created on July 17th, 2021 and contain detailed listings data, review data and calendar data of current Airbnb listings in Munich, Germany. This data was created by Murray Cox and his Inside Airbnb project which can be found here: http://insideairbnb.com/get-the-data.html\n",
    "\n",
    "**Methodology**: For the analysis I will use the CRISP-DM Methodology. CRIPS-DM stands for \"cross-industry process for data mining\". The process consists of six steps:\n",
    "\n",
    "1. Business Understanding\n",
    "2. Data Understanding\n",
    "3. Data Preparation\n",
    "4. Modeling\n",
    "5. Evaluation\n",
    "6. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Airbnb** is a community-driven platform that promotes amazing travel that is local, genuine, and one-of-a-kind. Airbnb has over 5 million listings and is present in 191 countries and over 81,000 cities. Through a concept intended to promote healthy travel, the Airbnb community has hosted over half a billion visitors to date.\n",
    "\n",
    "**Research questions**:\n",
    "1. What are the TOP 3 most expensive city districts for a stay in Munich in general?\n",
    "2. What are the TOP 3 factors influence the price for a stay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains the following files:\n",
    "* listings.csv: descriptions and review score\n",
    "* calendar.csv: listing id, price and availability for the upcoming year\n",
    "* reviews.csv: unique id for each reviewer and detailed comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = pd.read_csv(\"data/listings.csv\");\n",
    "df_calendar = pd.read_csv(\"data/calendar.csv\");\n",
    "df_reviews = pd.read_csv(\"data/reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 A glimpse of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we examine the overall features of each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"Calendar\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at a concise summary of the DataFrame 'calendar'\n",
    "df_calendar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first rows of the dataframe\n",
    "df_calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all features in this data set and show the number of missing values\n",
    "obj = df_calendar.isnull().sum()\n",
    "for key,value in obj.iteritems():\n",
    "    percent = round((value * 100 / df_calendar['listing_id'].index.size),3)\n",
    "    print(key,\", \",value, \"(\", percent ,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of the dataframe\n",
    "df_calendar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set consists of 7 features and a total rows of 1.860.770\n",
    "\n",
    "Only the features 'price' and 'adjusted price' contain missing data (both 180).\n",
    "\n",
    "The following data cleaning is suggested for further analysis:\n",
    "* Drop feature 'adjusted_price'.\n",
    "* Remove the rows in 'price' that have missing data (the number of impacted rows is minimal, 0.01 percent ).\n",
    "* The feature 'price' must be transformed to a numerical data type.\n",
    "* The 'date' feature must be changed to datetime format.\n",
    "* The attribute 'available' must be changed to a bool data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"Listings\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a closer look at a concise summary of the DataFrame 'listings'\n",
    "df_listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first rows of the dataframe\n",
    "df_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all features in this data set and show the number of missing values\n",
    "obj = df_listings.isnull().sum()\n",
    "for key,value in obj.iteritems():\n",
    "    percent = round((value * 100 / df_listings['id'].index.size),3)\n",
    "    print(key,\", \",value, \"(\", percent ,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of the dataframe\n",
    "df_listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count distinct observations per feature\n",
    "df_listings.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 74 features and a total rows of 5098.\n",
    "\n",
    "The overall quality is not satisfactory for all aspects. It must be decided how to handle the remaining missing data.\n",
    "\n",
    "Filling does not seem to be very promising in all instances, therefore the characteristics should be removed from a threshold.\n",
    "\n",
    "Some features have only constant values and don't help us any further.\n",
    "\n",
    "The following data cleaning is suggested for further analysis:\n",
    "\n",
    "* Drop features with constant values\n",
    "* Drop features with more than 50% missing data\n",
    "* Fill missing numerical data with mean value\n",
    "* Convert features to useable data type (e.g. price)\n",
    "* Drop features that do not provide us with any useful information (for our specific questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"Reviews\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at a concise summary of the DataFrame 'reviews'\n",
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first rows of the dataframe\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all features in this data set and show the number of missing values\n",
    "obj = df_reviews.isnull().sum()\n",
    "for key,value in obj.iteritems():\n",
    "    percent = round((value * 100 / df_reviews['id'].index.size),3)\n",
    "    print(key,\", \",value, \"(\", percent ,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of the dataframe\n",
    "df_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 6 features and a total of 106.971 rows.\n",
    "\n",
    "The overall quality is good, only the feature 'comments' has missing data (72).\n",
    "\n",
    "At the first sight the data set cannot be used to answer the questions. Nevertheless, the number of reviews shows an interesting pattern which should also be examined.\n",
    "\n",
    "The feature 'id' may be connected to the other datasets 'calendar' or 'listings'.\n",
    "\n",
    "Missing data in 'comments' can be dropped (number of affected rows is low ~0.04%) and the feature 'date' should be converted into 'DateTime' data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to address our business questions, we just need a few precise and important characteristics.\n",
    "\n",
    "**Location**:\n",
    "* neighbourhood_cleansed\n",
    "* latitude\n",
    "* longitude\n",
    "\n",
    "**Room**:\n",
    "* room_type\n",
    "* minimum_nights\n",
    "* maximum_nights\n",
    "* amenities\n",
    "\n",
    "**Price**:\n",
    "* price\n",
    "\n",
    "**Score**:\n",
    "* review_scores_rating\n",
    "* review_scores_accuracy\n",
    "* review_scores_cleanliness\n",
    "* review_scores_checkin\n",
    "* review_scores_communication\n",
    "* review_scores_location\n",
    "* review_scores_value\n",
    "* reviews_per_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Question 1: \"What are the TOP 3 most expensive city districts for a stay in Munich in general?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we clean the \"listings\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data to a new DataFrame\n",
    "df_listings_clean = df_listings.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data set \"listings\" according to our previous analysis\n",
    "\n",
    "# Drop unnecessary features\n",
    "features_to_drop = ['listing_url', 'picture_url','host_url', 'host_thumbnail_url', 'host_picture_url',\n",
    "                    'name', 'neighborhood_overview', 'description',\n",
    "                    'host_name', 'host_location', 'host_neighbourhood', 'last_scraped',\n",
    "                    'calendar_last_scraped', 'first_review', 'last_review', 'host_since', 'calendar_updated',\n",
    "                    'host_total_listings_count']\n",
    "df_listings_clean.drop(features_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove constant features by finding unique values per feature \n",
    "df_listings_clean = df_listings_clean[df_listings_clean.nunique().where(df_listings_clean.nunique()!=1).dropna().keys()]\n",
    "\n",
    "# Drop features with 50% or more missing values\n",
    "more_than_50 = list(df_listings_clean.columns[df_listings_clean.isnull().mean() > 0.5])\n",
    "df_listings_clean.drop(more_than_50, axis=1, inplace=True)\n",
    "\n",
    "# Clean up the format values\n",
    "df_listings_clean['price'] = df_listings_clean['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Convert rates type from string to float and remove the % sign\n",
    "df_listings_clean['host_response_rate'] = df_listings_clean['host_response_rate'].astype(str).str.replace('%', '').astype(float)\n",
    "df_listings_clean['host_response_rate'] = df_listings_clean['host_response_rate'] * 0.01\n",
    "df_listings_clean['host_acceptance_rate'] = df_listings_clean['host_acceptance_rate'].astype(str).str.replace('%', '').astype(float)\n",
    "df_listings_clean['host_acceptance_rate'] = df_listings_clean['host_acceptance_rate'] * 0.01\n",
    "\n",
    "# Covert boolean data from string data type to boolean\n",
    "boolean_features = ['instant_bookable', 'host_is_superhost', 'host_has_profile_pic', \n",
    "                'host_identity_verified']\n",
    "df_listings_clean[boolean_features] = df_listings_clean[boolean_features].replace({'t': True, 'f': False})\n",
    "\n",
    "# Fill numerical missing data with mean value\n",
    "numerical_feature = df_listings_clean.select_dtypes(np.number)\n",
    "numerical_columns = numerical_feature.columns\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imp_mean = imp_mean.fit(numerical_feature)\n",
    "\n",
    "df_listings_clean[numerical_columns] = imp_mean.transform(df_listings_clean[numerical_columns])\n",
    "     \n",
    "# Remove all remaining missing values  \n",
    "df_listings_clean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mean price for each neighbourhood_cleansed\n",
    "df_listings_clean.groupby([\"neighbourhood_cleansed\"])[\"price\"].describe().sort_values(\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature 'mean' with the mean price per neighbourhood\n",
    "df_listings_clean['mean'] = df_listings_clean.groupby('neighbourhood_cleansed')['price'].transform(lambda r : r.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for mean price per neighbourhood \n",
    "df_listings_plot = df_listings_clean\n",
    "df_listings_plot = df_listings_plot.groupby('neighbourhood_cleansed')[['price']].mean()\n",
    "df_listings_plot = df_listings_plot.reset_index()\n",
    "df_listings_plot = df_listings_plot.sort_values(by='price',ascending=False)\n",
    "df_listings_plot.plot.bar(x='neighbourhood_cleansed', y='price', color='blue', rot=90, figsize = (20,10)).set_title('Mean Price per city district (Neighbourhood)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map using the latitude and longitude data\n",
    "fig = px.scatter_mapbox(df_listings_clean, color=\"mean\", lat='latitude', lon='longitude',\n",
    "                        center=dict(lat=48.137154, lon=11.576124), zoom=10,\n",
    "                        mapbox_style=\"open-street-map\",width=1000, height=800);\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer for Question 1**\n",
    "\n",
    "The closer the city to the center of Munich, the higher the price\n",
    "The top 3 most expensive districts to stay in:\n",
    "* Altstadt-Lehel\n",
    "* Ludwigsvorstadt-Isarvorstadt\n",
    "* Tudering-Riem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data to a new DataFrame for encoding \n",
    "df_listings_encoded = df_listings_clean.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode features for use in machine learing model\n",
    "\n",
    "# Encode feature 'amenities' and concat the data\n",
    "df_listings_encoded.amenities = df_listings_encoded.amenities.str.replace('[{\"\"}]', \"\")\n",
    "df_amenities = df_listings_encoded.amenities.str.get_dummies(sep = \",\")\n",
    "df_listings_encoded = pd.concat([df_listings_encoded, df_amenities], axis=1) \n",
    "\n",
    "# Encode feature 'host_verification' and concat the data\n",
    "df_listings_encoded.host_verifications = df_listings_encoded.host_verifications.str.replace(\"['']\", \"\")\n",
    "df_verification = df_listings_encoded.host_verifications.str.get_dummies(sep = \",\")\n",
    "df_listings_encoded = pd.concat([df_listings_encoded, df_verification], axis=1)\n",
    "    \n",
    "# Encode feature 'host_response_time'\n",
    "dict_response_time = {'within an hour': 1, 'within a few hours': 2, 'within a day': 3, 'a few days or more': 4}\n",
    "df_listings_encoded['host_response_time'] = df_listings_encoded['host_response_time'].map(dict_response_time)\n",
    "\n",
    "# Encode the remaining categorical feature \n",
    "for categorical_feature in ['neighbourhood_cleansed', 'property_type', 'room_type',  'neighbourhood']:\n",
    "    df_listings_encoded = pd.concat([df_listings_encoded, \n",
    "                                     pd.get_dummies(df_listings_encoded[categorical_feature])],axis=1)\n",
    "\n",
    "# Drop features\n",
    "df_listings_encoded.drop(['amenities', 'neighbourhood_cleansed', 'property_type', 'room_type', \n",
    "                          'host_verifications', 'neighbourhood',\n",
    "                          'id', 'host_id', 'mean', 'latitude', 'longitude'],\n",
    "                         axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last check if there are any missing values in the data set\n",
    "sum(df_listings_encoded.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data to ensure a good distribution\n",
    "df_listings_encoded = shuffle(df_listings_encoded)\n",
    "\n",
    "X = df_listings_encoded.drop(['price'], axis=1)\n",
    "y = df_listings_encoded['price']\n",
    "\n",
    "# Split the data into random train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control shape after train-test-split\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
